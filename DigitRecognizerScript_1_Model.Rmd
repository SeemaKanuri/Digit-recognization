---
title: "DigitRecognizerScript final model"
author: "Seema Rani Kanuri"
date: "December 8, 2016"
output: pdf_document
---

#1st Model
## Introduction : Classify handwritten digits using the famous MNIST data

The goal is to take an image of a handwritten single digit, and determine what that digit is.

##Last project I did in python so I thought I should do this in R studio this is my 1st Model

I tried of using the convolutional neural network , CNN in Python but end up struggling a long time installing few packages and I spend vertually a long time on setting the framework for the required packages.However R seems to be an easy choice where I was able to do the analysis in a quick time.


## Data Preprocessing

The data for this competition were taken from the MNIST dataset. The MNIST ("Modified National Institute of Standards and Technology") dataset is a classic within the Machine Learning community that has been extensively studied.  

```{r setup, warning=F, results='hide'}
#install.packages("readr")
library(readr)
train<-read_csv("F:/OneDrive - Texas Tech University/MastersDocuments/DS- Multivariate Analysis/Digit Recognizer/train.csv")
test<-read_csv("F:/OneDrive - Texas Tech University/MastersDocuments/DS- Multivariate Analysis/Digit Recognizer/test.csv")

```

## Looking at the variables of leaf_train and leaf_test

The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.The `train.csv` has label column and 784 columns with values, the rest of the columns contain the pixel-values of the associated image that go from 0 to 255. (source:https://www.kaggle.com/c/digit-recognizer)

```{r }
#str(train)
#str(test)
head(train[1:10])
```

## Initializing h2o


```{r h2o-cluster, warning=F, echo=FALSE}
#install.packages("h2o")
#install.packages("statmod")

library(h2o)
library(statmod)
localH2O = h2o.init(max_mem_size = '15g', # use 16GB of RAM of *GB available
                    nthreads = -1) #nthreads -1 means use all cores
```

## Making data compatible with h2o using the `h2o` package

Initialize the h2o machine on local box
Load the csv as h20
I just convert the `train` and `test` sets into the h2o format using the `h2o` package

```{r , results='hide'}
train$label<-as.factor(train$label)
train_df = as.h2o(train)
test_df = as.h2o(test)

```

## Train model using the `h2o.deeplearning()` function  of the `h2o` package

2 hidden layers NN model with each of 3000 nodes and an epoch of 1000 and 0.5 dropout ratio in each

```{r myh2omodel,  warning=F, results='hide'}
myh2omodel =
  h2o.deeplearning(x = 2:785,  # column numbers for predictors
                   y = 1,   # column number for label
                   training_frame = train_df, # data in H2O format
                   activation = "RectifierWithDropout", # algorithm
                   input_dropout_ratio = 0.2, # % of inputs dropout
                   hidden_dropout_ratios = c(0.5,0.5), # % for nodes dropout
                   balance_classes = TRUE, 
                   hidden = c(2500,2500), # two layers of 3000 nodes
                   momentum_stable = 0.99,
                   nesterov_accelerated_gradient = T, # use it for speed
                   epochs = 1000) # no. of epochs
```

## Predicting the values for the test data

```{r precited_values, ,  warning=F, results='hide'}
precited_values <- h2o.predict(myh2omodel, test_df)
```

## Using the `h2o` package converting into the `h2o` format into data frame 

## And saving the predicted values of test in Output file

```{r}
predicted_values_df = as.data.frame(precited_values)
predicted_values_df = data.frame(ImageId = seq(1,length(predicted_values_df$predict)), Label = predicted_values_df$predict)
write.csv(predicted_values_df, file = "F:/OneDrive - Texas Tech University/MastersDocuments/DS- Multivariate Analysis/Digit Recognizer/myOutput-3000Nodes-2Layers-h2o.csv", row.names=F)

```

## Shutting down the `h2o`

```{r}
h2o.shutdown(prompt = F)
```

## Conclusion

I tried of using the convolutional neural network , CNN in Python but end up struggling a long time installing few packages and I spend vertually a long time on setting the framework for the required packages.

However R seems to be an easy choice where I was able to do the analysis in a quick time. To train the data I have used 2 hidden layers NN model with each of 3000 nodes and an epoch of 1000 using the `h2o` package on a subset lof data which lasted for longer than 40 minutes. 

Apart from  2 hidden layer NN using the `h2o` package, I alos tried `xgboost` and ` ` models.
However the best accuracy I got is with H2O 2 hidden layer NN with accuracy score of 0.97971

```{r}

```

## Resources used

[Deep Learning](http://spark.rstudio.com/h2o.html#deep_learning)

[Classification and Regression with H2O Deep Learning](http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/deeplearning/index.html)

[Defining a Deep Learning Model](http://h2o-release.s3.amazonaws.com/h2o/rel-lambert/5/docs-website/datascience/machlearning.html)

[Deep Learning with H2O](https://www.r-bloggers.com/things-to-try-after-user-part-1-deep-learning-with-h2o/)
